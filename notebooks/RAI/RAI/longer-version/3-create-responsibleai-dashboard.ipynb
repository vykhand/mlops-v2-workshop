{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r lib/requirements.txt"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682027778948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1682027779318
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1682027782487
        },
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Environment, BuildContext\n",
        "from azureml.mlflow import register_model\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "resource_group = \"<RESOURCE_GROUP>\"\n",
        "workspace = \"<AML_WORKSPACE_NAME>\"\n",
        "\n",
        "#connect to the workspace\n",
        "registry_name = \"azureml\"\n",
        "\n",
        "#credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace,)\n",
        "\n",
        "ml_client_registry = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace, registry_name)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1682027782889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"trainingcompute\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027783328
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "all_compute_names = [x.name for x in ml_client.compute.list()]\n",
        "\n",
        "if compute_name in all_compute_names:\n",
        "    print(f\"Found existing compute: {compute_name}\")\n",
        "else:\n",
        "    my_compute = AmlCompute(\n",
        "        name=compute_name,\n",
        "        size=\"Standard_DS2_v2\",\n",
        "        min_instances=0,\n",
        "        max_instances=4,\n",
        "        idle_time_before_scale_down=3600\n",
        "    )\n",
        "    ml_client.compute.begin_create_or_update(my_compute)\n",
        "    print(\"Initiated compute creation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute: trainingcompute\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027784565
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_hospital_version_string = '1'\n",
        "version='1'"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027784986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'rai_hospital_model'"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682027785369
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = ml_client.models.list(name=model_name)\n",
        "model = models.next()\n",
        "latest_model_version = model.version\n",
        "\n",
        "\n",
        "expected_model_id = f'rai_hospital_model:{latest_model_version}'\n",
        "azureml_model_id = f'azureml:{expected_model_id}'"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027785783
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_numerical_data(dataset):\n",
        "    dataset = dataset.drop([target_column], axis = 1)  \n",
        "    categorical = []\n",
        "    for col, value in dataset.iteritems():\n",
        "        if value.dtype == 'object' or value.dtype == 'bool':\n",
        "            categorical.append(col)\n",
        "    numerical = dataset.columns.difference(categorical)\n",
        "    return categorical, numerical"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027786144
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_parquet('data/training_data.parquet')\n",
        "test_data = pd.read_parquet('data/testing_data.parquet')"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1682027786587
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "\r\n",
        "hospital_train_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/training_data.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "hospital_test_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/testing_data.parquet\", mode=\"download\"\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682027787028
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = \"readmit_status\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1682027787419
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get categorical and numerical fields from training data\n",
        "categorical, numerical = get_categorical_numerical_data(train_data)\n",
        "print(\"categorical columns: \",  categorical)\n",
        "print(\"numerical field: \", numerical)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "categorical columns:  ['race', 'gender', 'age', 'discharge_destination', 'admission_source', 'primary_diagnosis', 'max_glu_serum', 'A1Cresult', 'insulin', 'diabetes_Med_prescribe', 'medicare', 'medicaid']\nnumerical field:  Index(['num_lab_procedures', 'num_medications', 'num_procedures',\n       'number_diagnoses', 'prior_emergency', 'prior_inpatient',\n       'prior_outpatient', 'time_in_hospital'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027787672
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"latest\"\n",
        "\n",
        "rai_constructor_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
        ")\n",
        "\n",
        "# We get latest version and use the same version for all components\n",
        "version = rai_constructor_component.version\n",
        "\n",
        "rai_explanation_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
        ")\n",
        "\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
        ")\n",
        "\n",
        "rai_gather_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682027788052
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from azure.ai.ml import dsl, Input\n",
        "\n",
        "@dsl.pipeline(\n",
        "        compute=compute_name,\n",
        "        description=\"RAI computation on hospital readmit classification data\",\n",
        "        experiment_name= \"RAI_hospital_Classification_RAIInsights_Computation_{rai_hospital_version_string}\",\n",
        "    )\n",
        "def rai_classification_pipeline(\n",
        "        target_column_name,\n",
        "        training_data,\n",
        "        testing_data\n",
        "    ):\n",
        "        # Initiate the RAIInsights\n",
        "        create_rai_job = rai_constructor_component(\n",
        "            title=\"RAI Dashboard\",\n",
        "            task_type=\"classification\",\n",
        "            model_info=expected_model_id,\n",
        "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),            \n",
        "            train_dataset=training_data,\n",
        "            test_dataset=testing_data,\n",
        "            target_column_name=target_column_name,\n",
        "            categorical_column_names=json.dumps(categorical),\n",
        "        )\n",
        "        create_rai_job.set_limits(timeout=120)\n",
        "        \n",
        "        # Add an explanation\n",
        "        explain_job = rai_explanation_component(\n",
        "            comment=\"Explanation for hospital remitted less than 30days  classification\",\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        )\n",
        "        explain_job.set_limits(timeout=120)\n",
        "        \n",
        "        # Add error analysis\n",
        "        erroranalysis_job = rai_erroranalysis_component(\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        )\n",
        "        erroranalysis_job.set_limits(timeout=120)\n",
        "\n",
        "        # Combine everything\n",
        "        rai_gather_job = rai_gather_component(\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
        "            insight_1=explain_job.outputs.explanation,\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\n",
        "        )\n",
        "        rai_gather_job.set_limits(timeout=120)\n",
        "\n",
        "        rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
        "        rai_gather_job.outputs.ux_json.mode = \"upload\"\n",
        "\n",
        "        return {\n",
        "            \"dashboard\": rai_gather_job.outputs.dashboard,\n",
        "            \"ux_json\": rai_gather_job.outputs.ux_json\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1682027788471
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "import webbrowser\r\n",
        "import time\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "\r\n",
        "\r\n",
        "    # open the pipeline in web browser\r\n",
        "    webbrowser.open(created_job.services[\"Studio\"].endpoint)\r\n",
        "    \r\n",
        "    #assert created_job.status == 'Completed'\r\n",
        "    return created_job"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682027788773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import Output\n",
        "\n",
        "# Pipeline to construct the RAI Insights\n",
        "insights_pipeline_job = rai_classification_pipeline(\n",
        "    target_column_name=target_column,\n",
        "    training_data=hospital_train_parquet,\n",
        "    testing_data=hospital_test_parquet,\n",
        ")\n",
        "\n",
        "# Workaround to enable the download\n",
        "rand_path = str(uuid.uuid4())\n",
        "insights_pipeline_job.outputs.dashboard = Output(\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
        "    mode=\"upload\",\n",
        "    type=\"uri_folder\",\n",
        ")\n",
        "insights_pipeline_job.outputs.ux_json = Output(\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\n",
        "    mode=\"upload\",\n",
        "    type=\"uri_folder\",\n",
        ")\n",
        "\n",
        "\n",
        "# submit pipeline\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1682028002754
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}